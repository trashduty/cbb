name: Basketball Data Scraper

on:
  schedule:
    # Run every 15 minutes to capture rapid odds movements (injuries, sharp action)
    - cron: '*/15 * * * *'
  workflow_dispatch:  # Allow manual triggering

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install Node.js dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install UV
        run: pip install uv

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper pipeline
        run: node ./src/index.js
        env:
          EMAIL: ${{ secrets.EMAIL }}
          PASSWORD: ${{ secrets.PASSWORD }}
          ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
          KENPOM_API_KEY: ${{ secrets.KENPOM_API_KEY }}

      - name: Grade completed games (before filtering)
        run: uv run src/scrapers/grade_bets.py
        env:
          ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}

      - name: Filter out started games
        run: python src/utils/filter_started_games.py

      - name: Generate model record report
        run: uv run src/utils/generate_model_record.py

      - name: Copy CSV to docs folder
        run: cp CBB_Output.csv docs/CBB_Output.csv

      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add CBB_Output.csv historical_data/ data/kp.csv data/kp_mapped.csv graded_results.csv game_snapshots.csv model_record.csv docs/
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update CBB_Output.csv - $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
            # Pull with rebase to handle any commits made during this run
            # Use --autostash to handle any unstaged changes from the scraper run
            git pull --rebase --autostash origin ${GITHUB_REF#refs/heads/}
            git push origin HEAD:${GITHUB_REF}
          fi